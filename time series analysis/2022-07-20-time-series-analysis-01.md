## 0. 시계열 데이터란?
- 시간 $(1, 2, ···, n)$ 순서에 따라 수집된 데이터의 수열 $(x_{1}, x_{2}, ..., x_{n})$을 의미하며, 이 때 시간의 간격은 같아야 함
- 일정한 시간 간격에 따라 소비자물가지수, 코스피 지수, 일사량 등을 측정(or 수집)한 것이 대표적인 시계열 데이터라고 할 수 있음 


## 1. White noise(백색잡음)
- noise란 외부요소로 인해 시계열 데이터의 추세성을 흐리는 것이다.
- 시계열 데이터에는 항상 noise가 있으므로, 이 noise를 제대로 컨트롤해야 시계열의 추세성을 제대로 파악할 수 있다.
- 이를 위해 우리는 white noise에 몇 가지 가정을 한다. 시간 $(1, 2, ···, n)$의 White noise를 $(w_{1}, w_{2}, ..., w_{n})$이라고 할 때, 
    1. 서로 다른 두 시점 $t$와 $s$에 대해 $Cov(w_{s}, w_{t})=0$이다. 즉, 두 시점의 white noise 간 선형적 상관관계가 없다.
    2. $E(w_{t})=0$이다. White noise의 평균을 $0$으로 만들어 계산을 간편하게 할 수 있다. 이것을 centering 또는 demeaning이라고 부른다.
    3. $Var(w_{t})=\sigma_{w}^2$이다. 어느 시점의 white noise이든, 시점 $t$에 관계 없이 일정하다.
- 위의 가정을 종합하면, $w_{t}\sim WN(0, \sigma_{w}^2)$로 나타낼 수 있고, 일반적으로 white noise에 대해 정규분포를 가정하므로 $w_{t}\sim N(0, \sigma_{w}^2)$가 된다. 여기에 더해, 각 시점 별 white noise들은 $i.i.d$이다.
- White noise의 경우, 아래와 같이 그려질 수 있다.
```r
iter = 300
wn = rep(NA, iter)
for (i in 1:iter) {
  wn[i] = mean(rnorm(100, 0, 1))
}
plot(wn, type='l', main="White noise")
abline(h=c(-0.2, 0, 0.2), col=c('black', 'red', 'black'), lwd=2)
```

![whitenoise](assets/images/TILphotos/whitenoise.png){: width="70%" height="70%"}


## 2. 정상성(Stationarity)
- stationary란 사전적으로 '변화 없는, 움직이지 않는'이란 의미를 가지고 있다. 시계열 분석에서 정상성이란 시간이 지나도 시계열의 확률적 특징들이 변하지 않음, 즉 확률 분포가 변하지 않음을 뜻한다. 시계열 분석에서 정상성이 중요한 이유는 정상성이 성립되어야 예측이 가능하기 때문이다.
### 1) 강정상성(Strong stationarity)
- 시간을 통쨰로 $h$만큼 shift 하더라도 시간 $(1, 2, ···, n)$과 시간 $(1+h, 2+h, ···, n+h)$의 결합확률분포가 변하지 않는다는 의미이다.  
즉,  
$F_{X_{1}, X_{2}, ..., X_{n+h}}(x_{1}, x_{2}, ..., x_{n})
=P(X_{1} \leq x_{1}, X_{2} \leq x_{2}, ..., X_{n} \leq x_{n})$이라고 할 때, 아래의 식이 성립한다는 의미이다.
$$F_{X_{1}, X_{2}, ..., X_{n+h}}(x_{1}, x_{2}, ..., x_{n})
=F_{X_{1+h}, X_{2+h}, ..., X_{n+h}}(x_{1}, x_{2}, ..., x_{n})$$
- 그러나 시계열 모형이 주어졌을 때 강정상성을 확인하는 것이 현실적으로 어려우므로 우리는 조금 더 약한 가정을 한다.

### 2) 약정상성(Weak stationarity)
- 약정상성은 강정상성과 다르게 분포에 대한 조건은 없지만, 아래의 세 개 조건을 만족해야 한다.
  1. $E(X_{t})$는 일정하다. (반드시 0일 필요는 없으며, 어떤 상수로 일정하면 됨)
  2. 서로 다른 두 시점 $t$, $s$에 대하여 $Cov(X_{t}, X_{s})=Cov(X_{t+h}, X_{s+h})$이다.
  3. $\gamma_{X}(h)=Cov(X_{t}, X_{t+h})$이 성립한다. 즉, $X_{t}$과 $X_{t+h}$의 공분산은 오직 $h$에 대해서만 의존적이다.
